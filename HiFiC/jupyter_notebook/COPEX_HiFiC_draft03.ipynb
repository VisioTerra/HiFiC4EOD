{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac22576-64c4-4ab0-8325-f9957b4ce022",
   "metadata": {},
   "source": [
    "# COPEX HiFiC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f043948-cc3c-4570-8b8e-70196cc5ac8e",
   "metadata": {},
   "source": [
    "## table of content:\n",
    "- [Initialisation du projet](#Initialisation-du-projet)\n",
    "- [Decompression](#Decompression)\n",
    "- [Compressed vs Decompressed](#Compressed-vs-Decompressed)\n",
    "- [Flooding USE CASE](#Flooding-USE-CASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883f5e7-3222-4751-a1a4-38351a795830",
   "metadata": {},
   "source": [
    "# Initialisation du projet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540cb5c9-cd15-49cd-b2cf-cda3b08523f2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136bdb61-2885-4675-92a7-c0a9455db01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for downloading data\n",
    "from requests.auth import HTTPBasicAuth  # for authentication\n",
    "import os # for proper path handling\n",
    "import torch # for ai\n",
    "import time # to get downloading and execution time\n",
    "from tqdm import tqdm  # to have progression bars\n",
    "import panel as pn # graphic interface to do comparisons\n",
    "from PIL import Image # for image management\n",
    "import numpy as np # image to panel hadling\n",
    "import matplotlib.pyplot as plt # for visualisation\n",
    "import matplotlib.image as mpimg # for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6579d7b-5e4f-4357-9a03-c3e8904064c5",
   "metadata": {},
   "source": [
    "## Test GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3818a4-bdf7-4401-a7a7-5c206dac6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.3.0.dev20240305+cu121\n",
      "Version de CUDA disponible: 12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\",torch.__version__)\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # print cuda version\n",
    "    print(f\"Version de CUDA disponible: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"CUDA n'est pas disponible sur ce système.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cad2fd-ecf4-4879-85c6-5c0ee04fc1ae",
   "metadata": {},
   "source": [
    "## Data downloading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd360b0-097c-4e62-9cba-63ef623a236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_url_from_model_name(model_name):\n",
    "    \"\"\"return the url and final uncompressed filename\"\"\"\n",
    "    return \"https://www.visioterra.fr/telechargement/P382_ESRIN_COPEX-DCC/models/\"+model_name, model_name\n",
    "\n",
    "def download_model(model_name, output_folder, username, password,):\n",
    "    # make sure output folder exist, create it if not\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # full url to donwload file\n",
    "    url, model_final_name = original_url_from_model_name(model_name)\n",
    "    print(\"url = \",url)\n",
    "    # full output path for download\n",
    "    download_path = os.path.join(output_folder, model_name)\n",
    "    if os.path.exists(download_path) : \n",
    "        print(download_path,\"already downloaded.\")\n",
    "        return\n",
    "        \n",
    "    # athentication\n",
    "    auth = HTTPBasicAuth(username, password) \n",
    "\n",
    "    # Télécharger le fichier\n",
    "    begin_time = time.time()\n",
    "    #  get the total size for the progression bar\n",
    "    file_size = int(requests.head(url, auth=auth).headers['Content-Length'])\n",
    "     # download file\n",
    "    try :\n",
    "        with requests.get(url, auth=auth, stream=True) as response:\n",
    "            with open(download_path, 'wb') as file, tqdm(\n",
    "                    desc=f\"Downloading [{model_name}]\",\n",
    "                    total=file_size,\n",
    "                    unit=\"B\",\n",
    "                    unit_scale=True,\n",
    "                    unit_divisor=1024,\n",
    "            ) as bar:\n",
    "                for data in response.iter_content(chunk_size=1024):\n",
    "                    file.write(data)\n",
    "                    bar.update(len(data))\n",
    "    except :\n",
    "        print(exception)\n",
    "    end_time = time.time()\n",
    "    download_and_save_time = end_time - begin_time\n",
    "    print(download_path,\"downloaded in \",download_and_save_time,\"s.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee9f0b2-aaac-4d48-b2d4-a378b4e458fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recon_path(granule_id, output_folder) :\n",
    "    return os.path.join(output_folder,granule_id+\"_compressed_RECON.png\")\n",
    "    \n",
    "def compressed__high_url_from_granuleid(file_name):\n",
    "    \"\"\"return the url and final compressed filename\"\"\"\n",
    "    return \"https://www.visioterra.fr/telechargement/P382_ESRIN_COPEX-DCC/data_compressed/S1A_VH_L16_clamp_0_250_compressed_high/\"+file_name+\"_compressed.hfc\",file_name+\"_compressed.hfc\" \n",
    "\n",
    "def compressed__low_url_from_granuleid(file_name):\n",
    "    \"\"\"return the url and final compressed filename\"\"\"    \n",
    "    return \"https://www.visioterra.fr/telechargement/P382_ESRIN_COPEX-DCC/data_compressed/S1A_VH_L16_clamp_0_250_compressed_low/\"+file_name+\"_compressed.hfc\",file_name+\"_compressed.hfc\" \n",
    "\n",
    "def original_url_from_granuleid(file_name):\n",
    "    \"\"\"return the url and final uncompressed filename\"\"\"\n",
    "    return \"https://www.visioterra.fr/telechargement/P382_ESRIN_COPEX-DCC/data_uncompressed/S1A_VH_rgb_L16_clamp_0_250/\"+file_name+\".png\",file_name+\".png\" \n",
    "\n",
    "def download_data(granule_id, output_folder, username, password, compressed=True, compression_model=\"low\"):\n",
    "    # make sure output folder exist, create it if not\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # full url to donwload file\n",
    "    if compressed :  \n",
    "        if compression_model == \"low\" : url,filename = compressed__low_url_from_granuleid(granule_id)\n",
    "        if compression_model == \"high\" : url,filename = compressed__high_url_from_granuleid(granule_id)\n",
    "    if not compressed : url,filename = original_url_from_granuleid(granule_id)\n",
    "        \n",
    "    # full output path for download\n",
    "    download_path = os.path.join(output_folder, filename)\n",
    "    if os.path.exists(download_path) : \n",
    "        print(download_path,\"already downloaded.\")\n",
    "        return download_path,0\n",
    "        \n",
    "    # athentication\n",
    "    auth = HTTPBasicAuth(username, password) \n",
    "\n",
    "    # Télécharger le fichier\n",
    "    begin_time = time.time()\n",
    "    #  get the total size for the progression bar\n",
    "    file_size = int(requests.head(url, auth=auth).headers['Content-Length'])\n",
    "     # download file\n",
    "    try :\n",
    "        with requests.get(url, auth=auth, stream=True) as response:\n",
    "            with open(download_path, 'wb') as file, tqdm(\n",
    "                    desc=f\"Downloading [{filename}]\",\n",
    "                    total=file_size,\n",
    "                    unit=\"B\",\n",
    "                    unit_scale=True,\n",
    "                    unit_divisor=1024,\n",
    "            ) as bar:\n",
    "                for data in response.iter_content(chunk_size=1024):\n",
    "                    file.write(data)\n",
    "                    bar.update(len(data))\n",
    "    except :\n",
    "        print(exception)\n",
    "\n",
    "    end_time = time.time()\n",
    "    download_and_save_time = end_time - begin_time\n",
    "    print(download_path,\"downloaded in \",download_and_save_time,\"s.\")\n",
    "    return download_path,download_and_save_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76fea5be-520e-4db4-8136-d804f2d4cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\\originals\\S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12.png already downloaded.\n",
      "estimated time to download 200 original images :  0 s\n",
      "output\\compressed_high\\S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12_compressed.hfc already downloaded.\n",
      "estimated time to download 200 compressed images :  0 s\n",
      "output\\compressed_low\\S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12_compressed.hfc already downloaded.\n",
      "estimated time to download 200 compressed images :  0 s\n"
     ]
    }
   ],
   "source": [
    "granule_id = \"S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12\"\n",
    "output_folder = os.path.join(\"output\")\n",
    "originals_folder = os.path.join(output_folder,\"originals\")\n",
    "compressed_low_folder = os.path.join(output_folder,\"compressed_low\")\n",
    "compressed_high_folder = os.path.join(output_folder,\"compressed_high\")\n",
    "# usage example\n",
    "\n",
    "\n",
    "original_path , download_time = download_data(granule_id, originals_folder ,username=\"esa\",password=\"D25uXWjdjZEJ\", compressed= False)\n",
    "print(\"estimated time to download 200 original images : \",download_time*200,\"s\")\n",
    "\n",
    "_ , download_time = download_data(granule_id, compressed_high_folder ,username=\"esa\",password=\"D25uXWjdjZEJ\", compressed= True, compression_model=\"high\" )\n",
    "print(\"estimated time to download 200 compressed images : \",download_time*200,\"s\")\n",
    "\n",
    "_ , download_time = download_data(granule_id, compressed_low_folder ,username=\"esa\",password=\"D25uXWjdjZEJ\", compressed= True, compression_model=\"low\" )\n",
    "print(\"estimated time to download 200 compressed images : \",download_time*200,\"s\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f28001-cb9c-4fac-954a-6cf6fd31fce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of files in  output  :\n",
      "['compressed_high', 'compressed_low', 'decompressed_high', 'decompressed_low', 'flooding', 'originals']\n",
      "list of files in  output\\originals  :\n",
      "['S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12.png']\n",
      "list of files in  output\\compressed_low  :\n",
      "['logs', 'S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12_compressed.hfc']\n",
      "list of files in  output\\compressed_high  :\n",
      "['logs', 'S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12_compressed.hfc']\n"
     ]
    }
   ],
   "source": [
    "print(\"list of files in \",output_folder,\" :\")\n",
    "print(os.listdir(output_folder))\n",
    "print(\"list of files in \",originals_folder,\" :\")\n",
    "print(os.listdir(originals_folder))\n",
    "print(\"list of files in \",compressed_low_folder,\" :\")\n",
    "print(os.listdir(compressed_low_folder))\n",
    "print(\"list of files in \",compressed_high_folder,\" :\")\n",
    "print(os.listdir(compressed_high_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f489887-07a7-4b6f-af22-2cd4bbd9ca16",
   "metadata": {},
   "source": [
    "# Decompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4856c568-ec83-440f-8761-5861208d7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = os.path.join(\"models\")\n",
    "decompressed_low_folder = os.path.join(output_folder,\"decompressed_low\")\n",
    "decompressed_high_folder = os.path.join(output_folder,\"decompressed_high\")\n",
    "recon_path_low = get_recon_path(granule_id, decompressed_low_folder)\n",
    "recon_path_high = get_recon_path(granule_id, decompressed_high_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f48ee1-9a96-4832-840d-dea5d4968f9b",
   "metadata": {},
   "source": [
    "## Using model Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc35f8bc-9015-4db1-9f34-ce705b7be9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url =  https://www.visioterra.fr/telechargement/P382_ESRIN_COPEX-DCC/models/HIFIC_OID7_L16_10000_low.pt\n",
      "models\\HIFIC_OID7_L16_10000_low.pt already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#downloading model low\n",
    "model_low_name = \"HIFIC_OID7_L16_10000_low.pt\"\n",
    "download_model(model_name = model_low_name,username=\"esa\",password=\"D25uXWjdjZEJ\",output_folder = models_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e1dff5-86b7-4652-9e34-99c4661b2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_low_path = os.path.join(models_folder, model_low_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5fb93e4-31d1-4155-a0c3-b0d8cba831d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data from  output\\compressed_low\n",
      "only_decompress is true... getting the .hfc\n",
      "decompress working on device [ cuda ] \n",
      "Building prior probability tables...\n",
      "Setting up Perceptual loss...\n",
      "Loading model from: D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\high-fidelity-generative-compression-master\\src\\loss\\perceptual_similarity\\weights\\v0.1\\alex.pth\n",
      "...[net-lin [alex]] initialized\n",
      "...Done\n",
      "image [ output\\decompressed_low\\S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12_compressed_RECON.png ] already decompressed, getting to the next\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10_23_18 INFO - logger_setup: D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\high-fidelity-generative-compression-master\\compress.py\n",
      "\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]\n",
      " 89%|########9 | 57/64 [00:00<00:00, 523.40it/s]\n",
      "100%|##########| 64/64 [00:00<00:00, 291.16it/s]\n",
      "D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\pytorch_nightly_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\pytorch_nightly_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "10_23_23 INFO - load_model: Loading model ...\n",
      "10_23_23 INFO - load_model: MODEL TYPE: compression_gan\n",
      "10_23_23 INFO - load_model: MODEL MODE: evaluation\n",
      "10_23_23 INFO - load_model: Model(\n",
      "  (Encoder): Encoder(\n",
      "    (pre_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (asymmetric_pad): ReflectionPad2d((0, 1, 1, 0))\n",
      "    (post_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (conv_block1): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(1, 60, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block2): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(60, 120, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block3): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(120, 240, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block4): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(240, 480, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block5): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(480, 960, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block_out): Sequential(\n",
      "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (1): Conv2d(960, 220, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (Generator): Generator(\n",
      "    (pre_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (asymmetric_pad): ReflectionPad2d((0, 1, 1, 0))\n",
      "    (post_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (conv_block_init): Sequential(\n",
      "      (0): ChannelNorm2D()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): Conv2d(220, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_0): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_1): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_2): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_3): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_4): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_5): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_6): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_7): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_8): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (upconv_block1): Sequential(\n",
      "      (0): ConvTranspose2d(960, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block2): Sequential(\n",
      "      (0): ConvTranspose2d(480, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block3): Sequential(\n",
      "      (0): ConvTranspose2d(240, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block4): Sequential(\n",
      "      (0): ConvTranspose2d(120, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv_block_out): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(60, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (Hyperprior): Hyperprior(\n",
      "    (analysis_net): HyperpriorAnalysis(\n",
      "      (conv1): Conv2d(220, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), padding_mode=reflect)\n",
      "      (conv3): Conv2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), padding_mode=reflect)\n",
      "    )\n",
      "    (synthesis_mu): HyperpriorSynthesis(\n",
      "      (conv1): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv2): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv3): ConvTranspose2d(320, 220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (synthesis_std): HyperpriorSynthesis(\n",
      "      (conv1): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv2): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv3): ConvTranspose2d(320, 220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (hyperlatent_likelihood): HyperpriorDensity()\n",
      "    (hyperprior_entropy_model): HyperpriorEntropyModel(\n",
      "      (distribution): HyperpriorDensity()\n",
      "    )\n",
      "    (prior_density): PriorDensity()\n",
      "    (prior_entropy_model): PriorEntropyModel(\n",
      "      (distribution): PriorDensity()\n",
      "    )\n",
      "  )\n",
      "  (squared_difference): MSELoss()\n",
      "  (perceptual_loss): PerceptualLoss()\n",
      ")\n",
      "10_23_23 INFO - load_model: Trainable parameters:\n",
      "10_23_23 INFO - load_model: Encoder.conv_block1.1.weight - torch.Size([60, 1, 7, 7])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block1.1.bias - torch.Size([60])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block1.2.gamma - torch.Size([1, 60, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block1.2.beta - torch.Size([1, 60, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block2.1.weight - torch.Size([120, 60, 3, 3])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block2.1.bias - torch.Size([120])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block2.2.gamma - torch.Size([1, 120, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block2.2.beta - torch.Size([1, 120, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block3.1.weight - torch.Size([240, 120, 3, 3])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block3.1.bias - torch.Size([240])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block3.2.gamma - torch.Size([1, 240, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block3.2.beta - torch.Size([1, 240, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block4.1.weight - torch.Size([480, 240, 3, 3])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block4.1.bias - torch.Size([480])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block4.2.gamma - torch.Size([1, 480, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block4.2.beta - torch.Size([1, 480, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block5.1.weight - torch.Size([960, 480, 3, 3])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block5.1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block5.2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block5.2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block_out.1.weight - torch.Size([220, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Encoder.conv_block_out.1.bias - torch.Size([220])\n",
      "10_23_23 INFO - load_model: Generator.conv_block_init.0.gamma - torch.Size([1, 220, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.conv_block_init.0.beta - torch.Size([1, 220, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.conv_block_init.2.weight - torch.Size([960, 220, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.conv_block_init.2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.conv_block_init.3.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.conv_block_init.3.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_0.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_0.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_0.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_0.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_0.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_0.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_0.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_0.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_1.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_1.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_1.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_1.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_1.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_1.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_1.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_1.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_2.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_2.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_2.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_2.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_2.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_2.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_2.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_2.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_3.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_3.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_3.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_3.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_3.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_3.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_3.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_3.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_4.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_4.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_4.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_4.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_4.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_4.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_4.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_4.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_5.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_5.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_5.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_5.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_5.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_5.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_5.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_5.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_6.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_6.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_6.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_6.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_6.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_6.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_6.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_6.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_7.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_7.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_7.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_7.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_7.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_7.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_7.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_7.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_8.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_8.conv1.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_8.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.resblock_8.conv2.bias - torch.Size([960])\n",
      "10_23_23 INFO - load_model: Generator.resblock_8.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_8.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_8.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.resblock_8.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block1.0.weight - torch.Size([960, 480, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block1.0.bias - torch.Size([480])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block1.1.gamma - torch.Size([1, 480, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block1.1.beta - torch.Size([1, 480, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block2.0.weight - torch.Size([480, 240, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block2.0.bias - torch.Size([240])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block2.1.gamma - torch.Size([1, 240, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block2.1.beta - torch.Size([1, 240, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block3.0.weight - torch.Size([240, 120, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block3.0.bias - torch.Size([120])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block3.1.gamma - torch.Size([1, 120, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block3.1.beta - torch.Size([1, 120, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block4.0.weight - torch.Size([120, 60, 3, 3])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block4.0.bias - torch.Size([60])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block4.1.gamma - torch.Size([1, 60, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.upconv_block4.1.beta - torch.Size([1, 60, 1, 1])\n",
      "10_23_23 INFO - load_model: Generator.conv_block_out.1.weight - torch.Size([1, 60, 7, 7])\n",
      "10_23_23 INFO - load_model: Generator.conv_block_out.1.bias - torch.Size([1])\n",
      "10_23_23 INFO - load_model: Hyperprior.analysis_net.conv1.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_23 INFO - load_model: Hyperprior.analysis_net.conv1.bias - torch.Size([320])\n",
      "10_23_23 INFO - load_model: Hyperprior.analysis_net.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_23 INFO - load_model: Hyperprior.analysis_net.conv2.bias - torch.Size([320])\n",
      "10_23_23 INFO - load_model: Hyperprior.analysis_net.conv3.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_23 INFO - load_model: Hyperprior.analysis_net.conv3.bias - torch.Size([320])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_mu.conv1.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_mu.conv1.bias - torch.Size([320])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_mu.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_mu.conv2.bias - torch.Size([320])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_mu.conv3.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_mu.conv3.bias - torch.Size([220])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_std.conv1.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_std.conv1.bias - torch.Size([320])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_std.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_std.conv2.bias - torch.Size([320])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_std.conv3.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_23 INFO - load_model: Hyperprior.synthesis_std.conv3.bias - torch.Size([220])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_0 - torch.Size([320, 3, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_0 - torch.Size([320, 3, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_0 - torch.Size([320, 3, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_1 - torch.Size([320, 3, 3])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_1 - torch.Size([320, 3, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_1 - torch.Size([320, 3, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_2 - torch.Size([320, 3, 3])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_2 - torch.Size([320, 3, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_2 - torch.Size([320, 3, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_3 - torch.Size([320, 1, 3])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_3 - torch.Size([320, 1, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_3 - torch.Size([320, 1, 1])\n",
      "10_23_23 INFO - load_model: Hyperprior.prior_entropy_model.CDF - torch.Size([64, 1481])\n",
      "10_23_23 INFO - load_model: Hyperprior.prior_entropy_model.CDF_offset - torch.Size([64])\n",
      "10_23_23 INFO - load_model: Hyperprior.prior_entropy_model.CDF_length - torch.Size([64])\n",
      "10_23_23 INFO - load_model: Number of trainable parameters: 181463901\n",
      "10_23_23 INFO - load_model: Estimated model size (under fp32): 725.856 MB\n",
      "10_23_23 INFO - load_model: Model init 5.669s\n",
      "10_23_24 INFO - decompress: {'batch_size': 1, 'beta': 0.15, 'checkpoints_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16\\\\checkpoints', 'crop_size': 256, 'dataset': 'OID7_L16_10000', 'dataset_path': 'data/datasets/OID7_L16_10000', 'dataset_type': {'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65535.0, 'factor': 32767.5}, 'discriminator_steps': 1, 'figures_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16\\\\figures', 'force_set_gpu': False, 'gan_loss_type': 'non_saturating', 'gpu': 0, 'ignore_schedule': True, 'image_dims': (1, 256, 256), 'k_M': 0.00234375, 'k_P': 1.0, 'lambda_A': 2, 'lambda_A_map': {'low': 2, 'med': 1, 'high': 0.5}, 'lambda_B': 0.0625, 'lambda_schedule': {'vals': [2.0, 1.0], 'steps': [50000]}, 'latent_channels': 220, 'latent_channels_DLMM': 64, 'latent_dims': (220, 16, 16), 'learning_rate': 0.0001, 'likelihood_type': 'gaussian', 'log_interval': 150, 'lr_schedule': {'vals': [1.0, 0.1], 'steps': [500000]}, 'mixture_components': 4, 'model_mode': 'training', 'model_type': 'compression_gan', 'multigpu': False, 'n_data': 10000, 'n_epochs': 8, 'n_residual_blocks': 9, 'n_steps': 1000000, 'name': 'OID7_L16_10000_compression_gan_2024_03_11_10_16', 'noise_dim': 32, 'normalize_input_image': False, 'regime': 'low', 'sample_noise': False, 'save': True, 'save_interval': 50000, 'shuffle': True, 'silent': True, 'snapshot': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16', 'storage_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16\\\\storage', 'target_rate': 0.14, 'target_rate_map': {'low': 0.14, 'med': 0.3, 'high': 0.45}, 'target_schedule': {'vals': [1.4285714285714286, 1.0], 'steps': [50000]}, 'tensorboard_runs': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16\\\\tensorboard', 'timestamp': '2024_03_11_11_20', 'use_channel_norm': True, 'use_latent_mixture_model': False, 'warmstart': True, 'warmstart_ckpt': 'experiments/OID7_L16_10000_compression_2024_03_07_18_37/checkpoints/OID7_L16_10000_compression_2024_03_07_18_37_epoch7_idx20000_2024_03_07_20_06.pt', 'weight_decay': 1e-06, '_get_args': <bound method _AttributeHolder._get_args of Namespace(ckpt_path='models\\\\HIFIC_OID7_L16_10000_low.pt', image_dir='output\\\\compressed_low', output_dir='output\\\\decompressed_low', batch_size=1, reconstruct=False, save=True, metrics=False, data_type={'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, only_compress=False, only_decompress=True)>, '_get_kwargs': <bound method _AttributeHolder._get_kwargs of Namespace(ckpt_path='models\\\\HIFIC_OID7_L16_10000_low.pt', image_dir='output\\\\compressed_low', output_dir='output\\\\decompressed_low', batch_size=1, reconstruct=False, save=True, metrics=False, data_type={'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, only_compress=False, only_decompress=True)>, 'ckpt_path': 'models\\\\HIFIC_OID7_L16_10000_low.pt', 'data_type': {'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, 'image_dir': 'output\\\\compressed_low', 'metrics': False, 'only_compress': False, 'only_decompress': True, 'output_dir': 'output\\\\decompressed_low', 'reconstruct': False}\n",
      "10_23_24 INFO - decompress: Building hyperprior probability tables...\n",
      "\n",
      "  0%|          | 0/320 [00:00<?, ?it/s]\n",
      "100%|##########| 320/320 [00:00<00:00, 3401.79it/s]\n",
      "10_23_26 INFO - decompress: All tables built.\n",
      "\n",
      "decompression en cours:   0%|          | 0/1 [00:00<?, ?image/s]\n",
      "decompression en cours: 100%|##########| 1/1 [00:00<?, ?image/s]\n"
     ]
    }
   ],
   "source": [
    "!python ../high-fidelity-generative-compression-master/compress.py -i {compressed_low_folder} -ckpt {model_low_path} --save --output_dir {decompressed_low_folder} --only_decompress True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ae224-9c21-42d0-af0f-aafec70b658c",
   "metadata": {},
   "source": [
    "## Using model high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b63489a9-4fc2-4257-b5ea-17654b7339cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url =  https://www.visioterra.fr/telechargement/P382_ESRIN_COPEX-DCC/models/HIFIC_OID7_L16_10000_high.pt\n",
      "models\\HIFIC_OID7_L16_10000_high.pt already downloaded.\n"
     ]
    }
   ],
   "source": [
    "#downloading model high\n",
    "model_high_name = \"HIFIC_OID7_L16_10000_high.pt\"\n",
    "download_model(model_name = model_high_name,username=\"esa\",password=\"D25uXWjdjZEJ\",output_folder = models_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827d526b-c296-4b51-85e9-794d0544b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_high_path = os.path.join(models_folder, model_high_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "555885bc-9a57-488e-8426-30d4fbbc8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data from  output\\compressed_high\n",
      "only_decompress is true... getting the .hfc\n",
      "decompress working on device [ cuda ] \n",
      "Building prior probability tables...\n",
      "Setting up Perceptual loss...\n",
      "Loading model from: D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\high-fidelity-generative-compression-master\\src\\loss\\perceptual_similarity\\weights\\v0.1\\alex.pth\n",
      "...[net-lin [alex]] initialized\n",
      "...Done\n",
      "image [ output\\decompressed_high\\S1A_IW_GRDH_1SDV_20160511T043458_20160511T043523_011206_010EF8_77F4_12_compressed_RECON.png ] already decompressed, getting to the next\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10_23_29 INFO - logger_setup: D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\high-fidelity-generative-compression-master\\compress.py\n",
      "\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]\n",
      " 89%|########9 | 57/64 [00:00<00:00, 520.79it/s]\n",
      "100%|##########| 64/64 [00:00<00:00, 292.86it/s]\n",
      "D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\pytorch_nightly_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\pytorch_nightly_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "10_23_31 INFO - load_model: Loading model ...\n",
      "10_23_31 INFO - load_model: MODEL TYPE: compression_gan\n",
      "10_23_31 INFO - load_model: MODEL MODE: evaluation\n",
      "10_23_31 INFO - load_model: Model(\n",
      "  (Encoder): Encoder(\n",
      "    (pre_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (asymmetric_pad): ReflectionPad2d((0, 1, 1, 0))\n",
      "    (post_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (conv_block1): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(1, 60, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block2): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(60, 120, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block3): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(120, 240, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block4): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(240, 480, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block5): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(480, 960, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block_out): Sequential(\n",
      "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (1): Conv2d(960, 220, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (Generator): Generator(\n",
      "    (pre_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (asymmetric_pad): ReflectionPad2d((0, 1, 1, 0))\n",
      "    (post_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (conv_block_init): Sequential(\n",
      "      (0): ChannelNorm2D()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): Conv2d(220, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_0): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_1): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_2): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_3): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_4): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_5): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_6): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_7): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_8): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (upconv_block1): Sequential(\n",
      "      (0): ConvTranspose2d(960, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block2): Sequential(\n",
      "      (0): ConvTranspose2d(480, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block3): Sequential(\n",
      "      (0): ConvTranspose2d(240, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block4): Sequential(\n",
      "      (0): ConvTranspose2d(120, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv_block_out): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(60, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (Hyperprior): Hyperprior(\n",
      "    (analysis_net): HyperpriorAnalysis(\n",
      "      (conv1): Conv2d(220, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), padding_mode=reflect)\n",
      "      (conv3): Conv2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), padding_mode=reflect)\n",
      "    )\n",
      "    (synthesis_mu): HyperpriorSynthesis(\n",
      "      (conv1): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv2): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv3): ConvTranspose2d(320, 220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (synthesis_std): HyperpriorSynthesis(\n",
      "      (conv1): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv2): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv3): ConvTranspose2d(320, 220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (hyperlatent_likelihood): HyperpriorDensity()\n",
      "    (hyperprior_entropy_model): HyperpriorEntropyModel(\n",
      "      (distribution): HyperpriorDensity()\n",
      "    )\n",
      "    (prior_density): PriorDensity()\n",
      "    (prior_entropy_model): PriorEntropyModel(\n",
      "      (distribution): PriorDensity()\n",
      "    )\n",
      "  )\n",
      "  (squared_difference): MSELoss()\n",
      "  (perceptual_loss): PerceptualLoss()\n",
      ")\n",
      "10_23_31 INFO - load_model: Trainable parameters:\n",
      "10_23_31 INFO - load_model: Encoder.conv_block1.1.weight - torch.Size([60, 1, 7, 7])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block1.1.bias - torch.Size([60])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block1.2.gamma - torch.Size([1, 60, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block1.2.beta - torch.Size([1, 60, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block2.1.weight - torch.Size([120, 60, 3, 3])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block2.1.bias - torch.Size([120])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block2.2.gamma - torch.Size([1, 120, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block2.2.beta - torch.Size([1, 120, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block3.1.weight - torch.Size([240, 120, 3, 3])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block3.1.bias - torch.Size([240])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block3.2.gamma - torch.Size([1, 240, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block3.2.beta - torch.Size([1, 240, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block4.1.weight - torch.Size([480, 240, 3, 3])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block4.1.bias - torch.Size([480])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block4.2.gamma - torch.Size([1, 480, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block4.2.beta - torch.Size([1, 480, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block5.1.weight - torch.Size([960, 480, 3, 3])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block5.1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block5.2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block5.2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block_out.1.weight - torch.Size([220, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Encoder.conv_block_out.1.bias - torch.Size([220])\n",
      "10_23_31 INFO - load_model: Generator.conv_block_init.0.gamma - torch.Size([1, 220, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.conv_block_init.0.beta - torch.Size([1, 220, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.conv_block_init.2.weight - torch.Size([960, 220, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.conv_block_init.2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.conv_block_init.3.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.conv_block_init.3.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_0.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_0.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_0.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_0.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_0.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_0.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_0.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_0.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_1.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_1.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_1.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_1.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_1.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_1.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_1.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_1.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_2.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_2.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_2.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_2.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_2.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_2.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_2.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_2.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_3.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_3.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_3.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_3.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_3.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_3.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_3.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_3.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_4.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_4.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_4.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_4.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_4.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_4.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_4.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_4.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_5.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_5.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_5.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_5.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_5.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_5.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_5.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_5.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_6.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_6.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_6.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_6.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_6.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_6.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_6.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_6.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_7.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_7.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_7.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_7.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_7.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_7.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_7.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_7.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_8.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_8.conv1.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_8.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.resblock_8.conv2.bias - torch.Size([960])\n",
      "10_23_31 INFO - load_model: Generator.resblock_8.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_8.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_8.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.resblock_8.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block1.0.weight - torch.Size([960, 480, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block1.0.bias - torch.Size([480])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block1.1.gamma - torch.Size([1, 480, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block1.1.beta - torch.Size([1, 480, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block2.0.weight - torch.Size([480, 240, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block2.0.bias - torch.Size([240])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block2.1.gamma - torch.Size([1, 240, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block2.1.beta - torch.Size([1, 240, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block3.0.weight - torch.Size([240, 120, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block3.0.bias - torch.Size([120])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block3.1.gamma - torch.Size([1, 120, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block3.1.beta - torch.Size([1, 120, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block4.0.weight - torch.Size([120, 60, 3, 3])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block4.0.bias - torch.Size([60])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block4.1.gamma - torch.Size([1, 60, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.upconv_block4.1.beta - torch.Size([1, 60, 1, 1])\n",
      "10_23_31 INFO - load_model: Generator.conv_block_out.1.weight - torch.Size([1, 60, 7, 7])\n",
      "10_23_31 INFO - load_model: Generator.conv_block_out.1.bias - torch.Size([1])\n",
      "10_23_31 INFO - load_model: Hyperprior.analysis_net.conv1.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_31 INFO - load_model: Hyperprior.analysis_net.conv1.bias - torch.Size([320])\n",
      "10_23_31 INFO - load_model: Hyperprior.analysis_net.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_31 INFO - load_model: Hyperprior.analysis_net.conv2.bias - torch.Size([320])\n",
      "10_23_31 INFO - load_model: Hyperprior.analysis_net.conv3.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_31 INFO - load_model: Hyperprior.analysis_net.conv3.bias - torch.Size([320])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_mu.conv1.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_mu.conv1.bias - torch.Size([320])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_mu.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_mu.conv2.bias - torch.Size([320])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_mu.conv3.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_mu.conv3.bias - torch.Size([220])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_std.conv1.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_std.conv1.bias - torch.Size([320])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_std.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_std.conv2.bias - torch.Size([320])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_std.conv3.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_31 INFO - load_model: Hyperprior.synthesis_std.conv3.bias - torch.Size([220])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_0 - torch.Size([320, 3, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_0 - torch.Size([320, 3, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_0 - torch.Size([320, 3, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_1 - torch.Size([320, 3, 3])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_1 - torch.Size([320, 3, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_1 - torch.Size([320, 3, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_2 - torch.Size([320, 3, 3])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_2 - torch.Size([320, 3, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_2 - torch.Size([320, 3, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_3 - torch.Size([320, 1, 3])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_3 - torch.Size([320, 1, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_3 - torch.Size([320, 1, 1])\n",
      "10_23_31 INFO - load_model: Hyperprior.prior_entropy_model.CDF - torch.Size([64, 1481])\n",
      "10_23_31 INFO - load_model: Hyperprior.prior_entropy_model.CDF_offset - torch.Size([64])\n",
      "10_23_31 INFO - load_model: Hyperprior.prior_entropy_model.CDF_length - torch.Size([64])\n",
      "10_23_31 INFO - load_model: Number of trainable parameters: 181463901\n",
      "10_23_31 INFO - load_model: Estimated model size (under fp32): 725.856 MB\n",
      "10_23_31 INFO - load_model: Model init 2.471s\n",
      "10_23_31 INFO - decompress: {'batch_size': 1, 'beta': 0.15, 'checkpoints_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_14_18_06\\\\checkpoints', 'crop_size': 256, 'data_type': {'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, 'dataset': 'OID7_L16_10000', 'dataset_path': 'data/datasets/OID7_L16_10000', 'discriminator_steps': 1, 'figures_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_14_18_06\\\\figures', 'force_set_gpu': False, 'gan_loss_type': 'non_saturating', 'gpu': 0, 'ignore_schedule': True, 'image_dims': (1, 256, 256), 'k_M': 0.00234375, 'k_P': 1.0, 'lambda_A': 0.5, 'lambda_A_map': {'vlow': 4, 'low': 2, 'med': 1, 'high': 0.5}, 'lambda_B': 0.0625, 'lambda_schedule': {'vals': [2.0, 1.0], 'steps': [50000]}, 'latent_channels': 220, 'latent_channels_DLMM': 64, 'latent_dims': (220, 16, 16), 'learning_rate': 0.0001, 'likelihood_type': 'gaussian', 'log_interval': 150, 'lr_schedule': {'vals': [1.0, 0.1], 'steps': [500000]}, 'mixture_components': 4, 'model_mode': 'training', 'model_type': 'compression_gan', 'multigpu': False, 'n_data': 10000, 'n_epochs': 8, 'n_residual_blocks': 9, 'n_steps': 1000000, 'name': 'OID7_L16_10000_compression_gan_2024_03_14_18_06', 'noise_dim': 32, 'normalize_input_image': False, 'only_compress': False, 'only_decompress': True, 'regime': 'high', 'sample_noise': False, 'save': True, 'save_interval': 50000, 'shuffle': True, 'silent': True, 'snapshot': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_14_18_06', 'storage_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_14_18_06\\\\storage', 'target_rate': 0.45, 'target_rate_map': {'vlow': 0.07, 'low': 0.14, 'med': 0.3, 'high': 0.45}, 'target_schedule': {'vals': [1.4285714285714286, 1.0], 'steps': [50000]}, 'tensorboard_runs': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_14_18_06\\\\tensorboard', 'timestamp': '2024_03_14_19_09', 'use_channel_norm': True, 'use_latent_mixture_model': False, 'warmstart': True, 'warmstart_ckpt': 'experiments/OID7_L16_10000_compression_2024_03_14_16_33/checkpoints/OID7_L16_10000_compression_2024_03_14_16_33_epoch7_idx20000_2024_03_14_18_02.pt', 'weight_decay': 1e-06, '_get_args': <bound method _AttributeHolder._get_args of Namespace(ckpt_path='models\\\\HIFIC_OID7_L16_10000_high.pt', image_dir='output\\\\compressed_high', output_dir='output\\\\decompressed_high', batch_size=1, reconstruct=False, save=True, metrics=False, data_type={'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, only_compress=False, only_decompress=True)>, '_get_kwargs': <bound method _AttributeHolder._get_kwargs of Namespace(ckpt_path='models\\\\HIFIC_OID7_L16_10000_high.pt', image_dir='output\\\\compressed_high', output_dir='output\\\\decompressed_high', batch_size=1, reconstruct=False, save=True, metrics=False, data_type={'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, only_compress=False, only_decompress=True)>, 'ckpt_path': 'models\\\\HIFIC_OID7_L16_10000_high.pt', 'image_dir': 'output\\\\compressed_high', 'metrics': False, 'output_dir': 'output\\\\decompressed_high', 'reconstruct': False}\n",
      "10_23_31 INFO - decompress: Building hyperprior probability tables...\n",
      "\n",
      "  0%|          | 0/320 [00:00<?, ?it/s]\n",
      "100%|##########| 320/320 [00:00<00:00, 3325.09it/s]\n",
      "10_23_37 INFO - decompress: All tables built.\n",
      "\n",
      "decompression en cours:   0%|          | 0/1 [00:00<?, ?image/s]\n",
      "decompression en cours: 100%|##########| 1/1 [00:00<?, ?image/s]\n"
     ]
    }
   ],
   "source": [
    "!python ../high-fidelity-generative-compression-master/compress.py -i {compressed_high_folder} -ckpt {model_high_path} --save --output_dir {decompressed_high_folder} --only_decompress True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e751511b-fa17-4c74-9450-1a9dcad934a0",
   "metadata": {},
   "source": [
    "# Compressed vs Decompressed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184c2f9a-5cd5-4f2b-b8d8-ed1d1427a7d8",
   "metadata": {},
   "source": [
    "Settings for panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdef5beb-0f58-4298-9ab0-a48b6591599f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1fc323af-391f-4ba5-baf4-7f1850b8d4cd'>\n",
       "  <div id=\"d02182e9-4a38-442e-9ccf-852c35dd8c70\" data-root-id=\"1fc323af-391f-4ba5-baf4-7f1850b8d4cd\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"77c54166-5bde-45b2-a569-c1b459659405\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"1fc323af-391f-4ba5-baf4-7f1850b8d4cd\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"a5440bfd-a2a4-4e44-ac31-5499f2d0c2f8\",\"attributes\":{\"plot_id\":\"1fc323af-391f-4ba5-baf4-7f1850b8d4cd\",\"comm_id\":\"dde67002744948f29e74b4c24bfd1d8d\",\"client_comm_id\":\"94bb561ce92a4d1abd4fb7b0de2190b5\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"77c54166-5bde-45b2-a569-c1b459659405\",\"roots\":{\"1fc323af-391f-4ba5-baf4-7f1850b8d4cd\":\"d02182e9-4a38-442e-9ccf-852c35dd8c70\"},\"root_ids\":[\"1fc323af-391f-4ba5-baf4-7f1850b8d4cd\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1fc323af-391f-4ba5-baf4-7f1850b8d4cd"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn.extension()\n",
    "pn.config.theme = 'dark'\n",
    "loading_text = pn.pane.Str(\n",
    "    'Processing request...',\n",
    "    styles={'font-size': '12pt'}\n",
    ")\n",
    "loading_gif = pn.pane.GIF('https://upload.wikimedia.org/wikipedia/commons/d/de/Ajax-loader.gif')\n",
    "loading = pn.Row(loading_gif, loading_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf779b-3f16-4a6f-854e-def737bf44ec",
   "metadata": {},
   "source": [
    "resizing function (keep image ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ff31a74-2a81-4c23-ac56-12aa44f3cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save(image_path, width):\n",
    "    # open image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Calculate new height while maintaining aspect ratio\n",
    "    orig_width, orig_height = image.size\n",
    "    height = int((width / orig_width) * orig_height)\n",
    "\n",
    "    # Resize image\n",
    "    resized_image = image.resize((width, height))\n",
    "\n",
    "    # Save resized image with \"_tmp\" added to file name\n",
    "    output_path = os.path.splitext(image_path)[0] + \"_tmp\" + os.path.splitext(image_path)[1]\n",
    "    resized_image.save(output_path)\n",
    "\n",
    "    # Supprimer l'image originale\n",
    "    # os.remove(image_path)\n",
    "\n",
    "    #print(\"L'image a été redimensionnée et enregistrée avec succès sous:\", output_path)\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec61784-15d2-4fcf-802a-26855d817408",
   "metadata": {},
   "source": [
    "display a comparison between original and decompressed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a1ac8-2abd-4ee3-884a-33ce9dca646d",
   "metadata": {},
   "source": [
    "## Comparison with low model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4039495-923a-426d-9965-fc5a6f3fb97b",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='a76cd55f-3a5d-4d7e-a730-338e1a35286c'>\n",
       "  <div id=\"b9823c82-11e2-49bb-9cfc-016281427d9b\" data-root-id=\"a76cd55f-3a5d-4d7e-a730-338e1a35286c\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"486b38f7-05ae-4631-9e45-f284c232982d\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"a76cd55f-3a5d-4d7e-a730-338e1a35286c\",\"attributes\":{\"name\":\"Row00126\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"c7a0d1d4-14ea-4039-a10a-5f2156d3e983\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"83a1a377-03e7-4992-85d8-e9df7b6864d3\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"5b441a7a-a82d-470e-845c-d86d41aa4155\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/dark.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"21e0b74e-2ce1-47c9-8822-7cae3638f45d\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/native.css\"}}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"77de09c7-d38d-43b9-bf06-adabb15bfded\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"c7a0d1d4-14ea-4039-a10a-5f2156d3e983\"},{\"id\":\"5b441a7a-a82d-470e-845c-d86d41aa4155\"},{\"id\":\"21e0b74e-2ce1-47c9-8822-7cae3638f45d\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/d/de/Ajax-loader.gif&quot;  style=&quot;max-width: 100%; max-height: 100%; object-fit: contain; width: auto; height: auto;&quot;&gt;&lt;/img&gt;\"}},{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"f2f13ccb-b6f4-48a7-bdf3-17ccfb98c222\",\"attributes\":{\"styles\":{\"type\":\"map\",\"entries\":[[\"font-size\",\"12pt\"]]},\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"c7a0d1d4-14ea-4039-a10a-5f2156d3e983\"},{\"id\":\"5b441a7a-a82d-470e-845c-d86d41aa4155\"},{\"id\":\"21e0b74e-2ce1-47c9-8822-7cae3638f45d\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt;Processing request...&lt;/pre&gt;\"}}]}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"a31babe7-36b9-43f3-ac67-335c52a82a3a\",\"attributes\":{\"plot_id\":\"a76cd55f-3a5d-4d7e-a730-338e1a35286c\",\"comm_id\":\"e2110e5fc1144dd295658dfa4b5e1eee\",\"client_comm_id\":\"0184c474f8f145079c9631bd349b8b14\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"486b38f7-05ae-4631-9e45-f284c232982d\",\"roots\":{\"a76cd55f-3a5d-4d7e-a730-338e1a35286c\":\"b9823c82-11e2-49bb-9cfc-016281427d9b\"},\"root_ids\":[\"a76cd55f-3a5d-4d7e-a730-338e1a35286c\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Row\n",
       "    [0] GIF(str)\n",
       "    [1] Str(str, styles={'font-size': '12pt'})"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "a76cd55f-3a5d-4d7e-a730-338e1a35286c"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_widget = pn.Row(loading_gif, pn.pane.Str('Processing request...',styles={'font-size': '12pt'}))\n",
    "display(display_widget) # loading screen while preparing next widget\n",
    "#resizing width to get better viewing experience\n",
    "img_width = 1500\n",
    "\n",
    "ori_resized = resize_and_save(original_path, width=img_width)\n",
    "rec_resized = resize_and_save(recon_path_low, width=img_width)\n",
    "\n",
    "display_widget.clear();\n",
    "#display_widget.append(pn.Swipe(original_path, recon_path_low,slider_width=3, slider_color =\"#00fff2\"))\n",
    "display_widget.append(pn.Swipe(ori_resized, rec_resized,slider_width=3, slider_color =\"#00fff2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ea90be0-eeec-464a-b34b-973599542769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing tmp resized images\n",
    "os.remove(ori_resized)\n",
    "os.remove(rec_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d58d429-f3db-42ef-b64a-00977bdb25e6",
   "metadata": {},
   "source": [
    "## Comparison with high model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b96cbee7-5686-459b-9412-b67300512c19",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='91f4796d-2aae-4874-b2b6-0bfb0da38c00'>\n",
       "  <div id=\"e912acc7-fb7c-4174-bd60-21e8ff230814\" data-root-id=\"91f4796d-2aae-4874-b2b6-0bfb0da38c00\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"3c7c79ae-6066-4886-84ca-08937ef1e148\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"91f4796d-2aae-4874-b2b6-0bfb0da38c00\",\"attributes\":{\"name\":\"Row00807\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"2acad353-6a32-4a6b-9070-19e0b424caf4\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"0ed716b4-e908-4e6d-8c3b-a928bffaa254\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"a8ee700b-d272-48f4-9762-e5b5a194c9b8\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/dark.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"880f93c9-8253-4b48-9052-9b23c964dcc9\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/native.css\"}}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"b5685d50-27d6-4b44-99c9-51f8474fc8bd\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"2acad353-6a32-4a6b-9070-19e0b424caf4\"},{\"id\":\"a8ee700b-d272-48f4-9762-e5b5a194c9b8\"},{\"id\":\"880f93c9-8253-4b48-9052-9b23c964dcc9\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/d/de/Ajax-loader.gif&quot;  style=&quot;max-width: 100%; max-height: 100%; object-fit: contain; width: auto; height: auto;&quot;&gt;&lt;/img&gt;\"}},{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"c2158a17-4889-44ce-9599-4bde89255756\",\"attributes\":{\"styles\":{\"type\":\"map\",\"entries\":[[\"font-size\",\"12pt\"]]},\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"2acad353-6a32-4a6b-9070-19e0b424caf4\"},{\"id\":\"a8ee700b-d272-48f4-9762-e5b5a194c9b8\"},{\"id\":\"880f93c9-8253-4b48-9052-9b23c964dcc9\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt;Processing request...&lt;/pre&gt;\"}}]}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"5c4fdf88-acf3-4d2f-a4f5-e33f9075f4da\",\"attributes\":{\"plot_id\":\"91f4796d-2aae-4874-b2b6-0bfb0da38c00\",\"comm_id\":\"9acd953e70494288a06e6a0baacf48a4\",\"client_comm_id\":\"0ed286019ce84a659d9476ec4d3c295f\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"3c7c79ae-6066-4886-84ca-08937ef1e148\",\"roots\":{\"91f4796d-2aae-4874-b2b6-0bfb0da38c00\":\"e912acc7-fb7c-4174-bd60-21e8ff230814\"},\"root_ids\":[\"91f4796d-2aae-4874-b2b6-0bfb0da38c00\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Row\n",
       "    [0] GIF(str)\n",
       "    [1] Str(str, styles={'font-size': '12pt'})"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "91f4796d-2aae-4874-b2b6-0bfb0da38c00"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_widget = pn.Row(loading_gif, pn.pane.Str('Processing request...',styles={'font-size': '12pt'}))\n",
    "display(display_widget) # loading screen while preparing next widget\n",
    "#resizing width to get better viewing experience\n",
    "img_width = 1500\n",
    "\n",
    "ori_resized = resize_and_save(original_path, width=img_width)\n",
    "rec_resized = resize_and_save(recon_path_high, width=img_width)\n",
    "\n",
    "display_widget.clear();\n",
    "#display_widget.append(pn.Swipe(original_path, recon_path_high,slider_width=3, slider_color =\"#00fff2\"))\n",
    "display_widget.append(pn.Swipe(ori_resized, rec_resized,slider_width=3, slider_color =\"#00fff2\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae87796-25ab-4c01-86e8-36d0e21934a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing tmp resized images\n",
    "os.remove(ori_resized)\n",
    "os.remove(rec_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41638873-1b6e-4e00-9b11-af62df54e779",
   "metadata": {},
   "source": [
    "## Comparison between low and high reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4aeb671-4157-4437-85cb-6b5c95ace159",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='6bb80d4d-a241-4354-a96d-b94e49834d03'>\n",
       "  <div id=\"dfa41ffc-f1ec-42ae-80d1-1c9b5586577b\" data-root-id=\"6bb80d4d-a241-4354-a96d-b94e49834d03\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"5adc40fd-ae44-43e1-9888-ce07891b2b0a\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"6bb80d4d-a241-4354-a96d-b94e49834d03\",\"attributes\":{\"name\":\"Row00162\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"c82a049f-c284-4a42-aa0f-e628ca798773\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"b18316c8-993c-4b68-a168-191c86745491\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"fa8db4c5-1f33-4e51-a969-2c759774ff89\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/dark.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"0fc2f9c1-d863-4899-8f05-60f5c0defc18\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/native.css\"}}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"0d580e3a-59f7-4802-a03f-63990e5b221e\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"c82a049f-c284-4a42-aa0f-e628ca798773\"},{\"id\":\"fa8db4c5-1f33-4e51-a969-2c759774ff89\"},{\"id\":\"0fc2f9c1-d863-4899-8f05-60f5c0defc18\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/d/de/Ajax-loader.gif&quot;  style=&quot;max-width: 100%; max-height: 100%; object-fit: contain; width: auto; height: auto;&quot;&gt;&lt;/img&gt;\"}},{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"d443f31c-5a10-4333-b538-adde0583298a\",\"attributes\":{\"styles\":{\"type\":\"map\",\"entries\":[[\"font-size\",\"12pt\"]]},\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"c82a049f-c284-4a42-aa0f-e628ca798773\"},{\"id\":\"fa8db4c5-1f33-4e51-a969-2c759774ff89\"},{\"id\":\"0fc2f9c1-d863-4899-8f05-60f5c0defc18\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt;Processing request...&lt;/pre&gt;\"}}]}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"145024a4-0beb-409c-8d57-4e6e411f3995\",\"attributes\":{\"plot_id\":\"6bb80d4d-a241-4354-a96d-b94e49834d03\",\"comm_id\":\"42614eee16c94e79b7249d536a349a16\",\"client_comm_id\":\"f9b07582513e4b41adadc34034184f14\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"5adc40fd-ae44-43e1-9888-ce07891b2b0a\",\"roots\":{\"6bb80d4d-a241-4354-a96d-b94e49834d03\":\"dfa41ffc-f1ec-42ae-80d1-1c9b5586577b\"},\"root_ids\":[\"6bb80d4d-a241-4354-a96d-b94e49834d03\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Row\n",
       "    [0] GIF(str)\n",
       "    [1] Str(str, styles={'font-size': '12pt'})"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "6bb80d4d-a241-4354-a96d-b94e49834d03"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_widget = pn.Row(loading_gif, pn.pane.Str('Processing request...',styles={'font-size': '12pt'}))\n",
    "display(display_widget) # loading screen while preparing next widget\n",
    "#resizing width to get better viewing experience\n",
    "img_width = 1500\n",
    "\n",
    "ori_resized = resize_and_save(recon_path_low, width=img_width)\n",
    "rec_resized = resize_and_save(recon_path_high, width=img_width)\n",
    "\n",
    "display_widget.clear();\n",
    "#display_widget.append(pn.Swipe(recon_path_low, recon_path_high,slider_width=3, slider_color =\"#00fff2\"))\n",
    "display_widget.append(pn.Swipe(ori_resized, rec_resized,slider_width=3, slider_color =\"#00fff2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "393cc87e-58de-478d-844f-37ae1d0557a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing tmp resized images\n",
    "os.remove(ori_resized)\n",
    "os.remove(rec_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70daa22-024a-4c37-be38-65d40f6814d5",
   "metadata": {},
   "source": [
    "# Flooding USE CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282bb907-e92f-4dbd-a6c6-0455f563eee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\\flooding\\S1A_IW_GRDH_1SDV_20210906T043536_20210906T043601_039556_04ACE3_18DD_12_compressed.hfc already downloaded.\n",
      "output\\flooding\\S1A_IW_GRDH_1SDV_20211129T043536_20211129T043601_040781_04D736_2E2A_12_compressed.hfc already downloaded.\n",
      "output\\flooding\\S1A_IW_GRDH_1SDV_20210906T043536_20210906T043601_039556_04ACE3_18DD_12.png already downloaded.\n",
      "output\\flooding\\S1A_IW_GRDH_1SDV_20211129T043536_20211129T043601_040781_04D736_2E2A_12.png already downloaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('output\\\\flooding\\\\S1A_IW_GRDH_1SDV_20211129T043536_20211129T043601_040781_04D736_2E2A_12.png',\n",
       " 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granule_id_dry = \"S1A_IW_GRDH_1SDV_20210906T043536_20210906T043601_039556_04ACE3_18DD_12\"\n",
    "granule_id_flooded = \"S1A_IW_GRDH_1SDV_20211129T043536_20211129T043601_040781_04D736_2E2A_12\"\n",
    "use_case_folder = os.path.join(output_folder,\"flooding\")\n",
    "\n",
    "#downloading compressed \n",
    "download_data(granule_id_dry, use_case_folder ,username=\"esa\",password=\"D25uXWjdjZEJ\", compressed= True, compression_model=\"low\" )\n",
    "download_data(granule_id_flooded, use_case_folder ,username=\"esa\",password=\"D25uXWjdjZEJ\", compressed= True, compression_model=\"low\" )\n",
    "\n",
    "#downloading originals for comparison purpose\n",
    "download_data(granule_id_dry, use_case_folder ,username=\"esa\",password=\"D25uXWjdjZEJ\", compressed= False)\n",
    "download_data(granule_id_flooded, use_case_folder ,username=\"esa\",password=\"D25uXWjdjZEJ\", compressed= False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096386aa-08a9-4133-b0a5-25f8e69c27a8",
   "metadata": {},
   "source": [
    "### decompressing (low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bc9f422-c4d4-4674-bee1-f50a5b0bd9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data from  output\\flooding\n",
      "only_decompress is true... getting the .hfc\n",
      "decompress working on device [ cuda ] \n",
      "Building prior probability tables...\n",
      "Setting up Perceptual loss...\n",
      "Loading model from: D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\high-fidelity-generative-compression-master\\src\\loss\\perceptual_similarity\\weights\\v0.1\\alex.pth\n",
      "...[net-lin [alex]] initialized\n",
      "...Done\n",
      "image [ output\\flooding\\S1A_IW_GRDH_1SDV_20210906T043536_20210906T043601_039556_04ACE3_18DD_12_compressed_RECON.png ] already decompressed, getting to the next\n",
      "image [ output\\flooding\\S1A_IW_GRDH_1SDV_20211129T043536_20211129T043601_040781_04D736_2E2A_12_compressed_RECON.png ] already decompressed, getting to the next\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10_23_42 INFO - logger_setup: D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\high-fidelity-generative-compression-master\\compress.py\n",
      "\n",
      "  0%|          | 0/64 [00:00<?, ?it/s]\n",
      " 89%|########9 | 57/64 [00:00<00:00, 514.99it/s]\n",
      "100%|##########| 64/64 [00:00<00:00, 293.07it/s]\n",
      "D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\pytorch_nightly_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\VisioTerra\\technique\\P382_ESRIN_COPEX-DCC\\engineering\\HiFiC.git\\HiFiC\\pytorch_nightly_venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "10_23_45 INFO - load_model: Loading model ...\n",
      "10_23_45 INFO - load_model: MODEL TYPE: compression_gan\n",
      "10_23_45 INFO - load_model: MODEL MODE: evaluation\n",
      "10_23_45 INFO - load_model: Model(\n",
      "  (Encoder): Encoder(\n",
      "    (pre_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (asymmetric_pad): ReflectionPad2d((0, 1, 1, 0))\n",
      "    (post_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (conv_block1): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(1, 60, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block2): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(60, 120, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block3): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(120, 240, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block4): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(240, 480, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block5): Sequential(\n",
      "      (0): ReflectionPad2d((0, 1, 1, 0))\n",
      "      (1): Conv2d(480, 960, kernel_size=(3, 3), stride=(2, 2), padding_mode=reflect)\n",
      "      (2): ChannelNorm2D()\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (conv_block_out): Sequential(\n",
      "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (1): Conv2d(960, 220, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (Generator): Generator(\n",
      "    (pre_pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (asymmetric_pad): ReflectionPad2d((0, 1, 1, 0))\n",
      "    (post_pad): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (conv_block_init): Sequential(\n",
      "      (0): ChannelNorm2D()\n",
      "      (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (2): Conv2d(220, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (3): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_0): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_1): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_2): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_3): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_4): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_5): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_6): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_7): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (resblock_8): ResidualBlock(\n",
      "      (pad): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (conv1): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (norm1): ChannelNorm2D()\n",
      "      (norm2): ChannelNorm2D()\n",
      "    )\n",
      "    (upconv_block1): Sequential(\n",
      "      (0): ConvTranspose2d(960, 480, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block2): Sequential(\n",
      "      (0): ConvTranspose2d(480, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block3): Sequential(\n",
      "      (0): ConvTranspose2d(240, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (upconv_block4): Sequential(\n",
      "      (0): ConvTranspose2d(120, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ChannelNorm2D()\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv_block_out): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(60, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (Hyperprior): Hyperprior(\n",
      "    (analysis_net): HyperpriorAnalysis(\n",
      "      (conv1): Conv2d(220, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), padding_mode=reflect)\n",
      "      (conv3): Conv2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), padding_mode=reflect)\n",
      "    )\n",
      "    (synthesis_mu): HyperpriorSynthesis(\n",
      "      (conv1): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv2): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv3): ConvTranspose2d(320, 220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (synthesis_std): HyperpriorSynthesis(\n",
      "      (conv1): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv2): ConvTranspose2d(320, 320, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
      "      (conv3): ConvTranspose2d(320, 220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (hyperlatent_likelihood): HyperpriorDensity()\n",
      "    (hyperprior_entropy_model): HyperpriorEntropyModel(\n",
      "      (distribution): HyperpriorDensity()\n",
      "    )\n",
      "    (prior_density): PriorDensity()\n",
      "    (prior_entropy_model): PriorEntropyModel(\n",
      "      (distribution): PriorDensity()\n",
      "    )\n",
      "  )\n",
      "  (squared_difference): MSELoss()\n",
      "  (perceptual_loss): PerceptualLoss()\n",
      ")\n",
      "10_23_45 INFO - load_model: Trainable parameters:\n",
      "10_23_45 INFO - load_model: Encoder.conv_block1.1.weight - torch.Size([60, 1, 7, 7])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block1.1.bias - torch.Size([60])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block1.2.gamma - torch.Size([1, 60, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block1.2.beta - torch.Size([1, 60, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block2.1.weight - torch.Size([120, 60, 3, 3])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block2.1.bias - torch.Size([120])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block2.2.gamma - torch.Size([1, 120, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block2.2.beta - torch.Size([1, 120, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block3.1.weight - torch.Size([240, 120, 3, 3])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block3.1.bias - torch.Size([240])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block3.2.gamma - torch.Size([1, 240, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block3.2.beta - torch.Size([1, 240, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block4.1.weight - torch.Size([480, 240, 3, 3])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block4.1.bias - torch.Size([480])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block4.2.gamma - torch.Size([1, 480, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block4.2.beta - torch.Size([1, 480, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block5.1.weight - torch.Size([960, 480, 3, 3])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block5.1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block5.2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block5.2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block_out.1.weight - torch.Size([220, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Encoder.conv_block_out.1.bias - torch.Size([220])\n",
      "10_23_45 INFO - load_model: Generator.conv_block_init.0.gamma - torch.Size([1, 220, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.conv_block_init.0.beta - torch.Size([1, 220, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.conv_block_init.2.weight - torch.Size([960, 220, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.conv_block_init.2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.conv_block_init.3.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.conv_block_init.3.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_0.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_0.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_0.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_0.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_0.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_0.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_0.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_0.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_1.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_1.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_1.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_1.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_1.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_1.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_1.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_1.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_2.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_2.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_2.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_2.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_2.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_2.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_2.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_2.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_3.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_3.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_3.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_3.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_3.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_3.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_3.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_3.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_4.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_4.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_4.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_4.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_4.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_4.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_4.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_4.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_5.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_5.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_5.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_5.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_5.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_5.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_5.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_5.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_6.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_6.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_6.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_6.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_6.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_6.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_6.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_6.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_7.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_7.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_7.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_7.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_7.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_7.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_7.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_7.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_8.conv1.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_8.conv1.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_8.conv2.weight - torch.Size([960, 960, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.resblock_8.conv2.bias - torch.Size([960])\n",
      "10_23_45 INFO - load_model: Generator.resblock_8.norm1.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_8.norm1.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_8.norm2.gamma - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.resblock_8.norm2.beta - torch.Size([1, 960, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block1.0.weight - torch.Size([960, 480, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block1.0.bias - torch.Size([480])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block1.1.gamma - torch.Size([1, 480, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block1.1.beta - torch.Size([1, 480, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block2.0.weight - torch.Size([480, 240, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block2.0.bias - torch.Size([240])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block2.1.gamma - torch.Size([1, 240, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block2.1.beta - torch.Size([1, 240, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block3.0.weight - torch.Size([240, 120, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block3.0.bias - torch.Size([120])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block3.1.gamma - torch.Size([1, 120, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block3.1.beta - torch.Size([1, 120, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block4.0.weight - torch.Size([120, 60, 3, 3])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block4.0.bias - torch.Size([60])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block4.1.gamma - torch.Size([1, 60, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.upconv_block4.1.beta - torch.Size([1, 60, 1, 1])\n",
      "10_23_45 INFO - load_model: Generator.conv_block_out.1.weight - torch.Size([1, 60, 7, 7])\n",
      "10_23_45 INFO - load_model: Generator.conv_block_out.1.bias - torch.Size([1])\n",
      "10_23_45 INFO - load_model: Hyperprior.analysis_net.conv1.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_45 INFO - load_model: Hyperprior.analysis_net.conv1.bias - torch.Size([320])\n",
      "10_23_45 INFO - load_model: Hyperprior.analysis_net.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_45 INFO - load_model: Hyperprior.analysis_net.conv2.bias - torch.Size([320])\n",
      "10_23_45 INFO - load_model: Hyperprior.analysis_net.conv3.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_45 INFO - load_model: Hyperprior.analysis_net.conv3.bias - torch.Size([320])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_mu.conv1.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_mu.conv1.bias - torch.Size([320])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_mu.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_mu.conv2.bias - torch.Size([320])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_mu.conv3.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_mu.conv3.bias - torch.Size([220])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_std.conv1.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_std.conv1.bias - torch.Size([320])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_std.conv2.weight - torch.Size([320, 320, 5, 5])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_std.conv2.bias - torch.Size([320])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_std.conv3.weight - torch.Size([320, 220, 3, 3])\n",
      "10_23_45 INFO - load_model: Hyperprior.synthesis_std.conv3.bias - torch.Size([220])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_0 - torch.Size([320, 3, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_0 - torch.Size([320, 3, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_0 - torch.Size([320, 3, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_1 - torch.Size([320, 3, 3])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_1 - torch.Size([320, 3, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_1 - torch.Size([320, 3, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_2 - torch.Size([320, 3, 3])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_2 - torch.Size([320, 3, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_2 - torch.Size([320, 3, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.H_3 - torch.Size([320, 1, 3])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.a_3 - torch.Size([320, 1, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.hyperlatent_likelihood.b_3 - torch.Size([320, 1, 1])\n",
      "10_23_45 INFO - load_model: Hyperprior.prior_entropy_model.CDF - torch.Size([64, 1481])\n",
      "10_23_45 INFO - load_model: Hyperprior.prior_entropy_model.CDF_offset - torch.Size([64])\n",
      "10_23_45 INFO - load_model: Hyperprior.prior_entropy_model.CDF_length - torch.Size([64])\n",
      "10_23_45 INFO - load_model: Number of trainable parameters: 181463901\n",
      "10_23_45 INFO - load_model: Estimated model size (under fp32): 725.856 MB\n",
      "10_23_45 INFO - load_model: Model init 2.506s\n",
      "10_23_45 INFO - decompress: {'batch_size': 1, 'beta': 0.15, 'checkpoints_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16\\\\checkpoints', 'crop_size': 256, 'dataset': 'OID7_L16_10000', 'dataset_path': 'data/datasets/OID7_L16_10000', 'dataset_type': {'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65535.0, 'factor': 32767.5}, 'discriminator_steps': 1, 'figures_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16\\\\figures', 'force_set_gpu': False, 'gan_loss_type': 'non_saturating', 'gpu': 0, 'ignore_schedule': True, 'image_dims': (1, 256, 256), 'k_M': 0.00234375, 'k_P': 1.0, 'lambda_A': 2, 'lambda_A_map': {'low': 2, 'med': 1, 'high': 0.5}, 'lambda_B': 0.0625, 'lambda_schedule': {'vals': [2.0, 1.0], 'steps': [50000]}, 'latent_channels': 220, 'latent_channels_DLMM': 64, 'latent_dims': (220, 16, 16), 'learning_rate': 0.0001, 'likelihood_type': 'gaussian', 'log_interval': 150, 'lr_schedule': {'vals': [1.0, 0.1], 'steps': [500000]}, 'mixture_components': 4, 'model_mode': 'training', 'model_type': 'compression_gan', 'multigpu': False, 'n_data': 10000, 'n_epochs': 8, 'n_residual_blocks': 9, 'n_steps': 1000000, 'name': 'OID7_L16_10000_compression_gan_2024_03_11_10_16', 'noise_dim': 32, 'normalize_input_image': False, 'regime': 'low', 'sample_noise': False, 'save': True, 'save_interval': 50000, 'shuffle': True, 'silent': True, 'snapshot': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16', 'storage_save': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16\\\\storage', 'target_rate': 0.14, 'target_rate_map': {'low': 0.14, 'med': 0.3, 'high': 0.45}, 'target_schedule': {'vals': [1.4285714285714286, 1.0], 'steps': [50000]}, 'tensorboard_runs': 'experiments\\\\OID7_L16_10000_compression_gan_2024_03_11_10_16\\\\tensorboard', 'timestamp': '2024_03_11_11_20', 'use_channel_norm': True, 'use_latent_mixture_model': False, 'warmstart': True, 'warmstart_ckpt': 'experiments/OID7_L16_10000_compression_2024_03_07_18_37/checkpoints/OID7_L16_10000_compression_2024_03_07_18_37_epoch7_idx20000_2024_03_07_20_06.pt', 'weight_decay': 1e-06, '_get_args': <bound method _AttributeHolder._get_args of Namespace(ckpt_path='models\\\\HIFIC_OID7_L16_10000_low.pt', image_dir='output\\\\flooding', output_dir='output\\\\flooding', batch_size=1, reconstruct=False, save=True, metrics=False, data_type={'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, only_compress=False, only_decompress=True)>, '_get_kwargs': <bound method _AttributeHolder._get_kwargs of Namespace(ckpt_path='models\\\\HIFIC_OID7_L16_10000_low.pt', image_dir='output\\\\flooding', output_dir='output\\\\flooding', batch_size=1, reconstruct=False, save=True, metrics=False, data_type={'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, only_compress=False, only_decompress=True)>, 'ckpt_path': 'models\\\\HIFIC_OID7_L16_10000_low.pt', 'data_type': {'dtype': 'L16', 'np_type': 'np.uint16', 'cent': 1.0, 'range': 65025.0, 'factor': 32512.5, 'ndim': 1}, 'image_dir': 'output\\\\flooding', 'metrics': False, 'only_compress': False, 'only_decompress': True, 'output_dir': 'output\\\\flooding', 'reconstruct': False}\n",
      "10_23_45 INFO - decompress: Building hyperprior probability tables...\n",
      "\n",
      "  0%|          | 0/320 [00:00<?, ?it/s]\n",
      " 93%|#########3| 298/320 [00:00<00:00, 2959.96it/s]\n",
      "100%|##########| 320/320 [00:00<00:00, 2999.67it/s]\n",
      "10_23_47 INFO - decompress: All tables built.\n",
      "\n",
      "decompression en cours:   0%|          | 0/2 [00:00<?, ?image/s]\n",
      "decompression en cours: 100%|##########| 2/2 [00:00<?, ?image/s]\n"
     ]
    }
   ],
   "source": [
    "!python ../high-fidelity-generative-compression-master/compress.py -i {use_case_folder} -ckpt {model_low_path} --save --output_dir {use_case_folder} --only_decompress True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c30f96b-3025-441c-abd2-ba26259675f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dry = os.path.join(use_case_folder,granule_id_dry+\".png\")\n",
    "original_flooded = os.path.join(use_case_folder,granule_id_flooded+\".png\")\n",
    "recon_dry = os.path.join(use_case_folder,granule_id_dry+\"_compressed_RECON.png\")\n",
    "recon_flooded = os.path.join(use_case_folder,granule_id_flooded+\"_compressed_RECON.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f105a17-a9d3-4932-96a9-f9edc5884554",
   "metadata": {},
   "source": [
    "### before | after (originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82e39902-259f-40c1-9fff-196bb2e6de2e",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='5b49adae-3caf-450f-a764-45f757610e09'>\n",
       "  <div id=\"c60dfea0-ffbf-4bc7-a3a4-c2bc9da30baa\" data-root-id=\"5b49adae-3caf-450f-a764-45f757610e09\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"35cd34cb-dcdf-46ea-94a3-1a73209d8491\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"5b49adae-3caf-450f-a764-45f757610e09\",\"attributes\":{\"name\":\"Row01099\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"9c526e55-f4fc-4e69-8add-fac93f69613e\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"eafe6880-e2a5-4402-97fc-19934d3143e9\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"db43abd0-8cc0-4889-8022-079618d9cc9c\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/dark.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"cd475f4a-3710-4b0e-9af3-272e905bc4f6\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/native.css\"}}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"d08ec673-5b7d-4446-ad73-1c7b4089fb1b\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9c526e55-f4fc-4e69-8add-fac93f69613e\"},{\"id\":\"db43abd0-8cc0-4889-8022-079618d9cc9c\"},{\"id\":\"cd475f4a-3710-4b0e-9af3-272e905bc4f6\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/d/de/Ajax-loader.gif&quot;  style=&quot;max-width: 100%; max-height: 100%; object-fit: contain; width: auto; height: auto;&quot;&gt;&lt;/img&gt;\"}},{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"0dffdd24-1a21-4a9f-ac26-a60927a4d9f0\",\"attributes\":{\"styles\":{\"type\":\"map\",\"entries\":[[\"font-size\",\"12pt\"]]},\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9c526e55-f4fc-4e69-8add-fac93f69613e\"},{\"id\":\"db43abd0-8cc0-4889-8022-079618d9cc9c\"},{\"id\":\"cd475f4a-3710-4b0e-9af3-272e905bc4f6\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt;Processing request...&lt;/pre&gt;\"}}]}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"9814d226-2426-4b73-8ccc-43674dc79efe\",\"attributes\":{\"plot_id\":\"5b49adae-3caf-450f-a764-45f757610e09\",\"comm_id\":\"a208bf0941c9456baea585727d14d513\",\"client_comm_id\":\"f82665380b134b049b0282466d591984\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"35cd34cb-dcdf-46ea-94a3-1a73209d8491\",\"roots\":{\"5b49adae-3caf-450f-a764-45f757610e09\":\"c60dfea0-ffbf-4bc7-a3a4-c2bc9da30baa\"},\"root_ids\":[\"5b49adae-3caf-450f-a764-45f757610e09\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Row\n",
       "    [0] GIF(str)\n",
       "    [1] Str(str, styles={'font-size': '12pt'})"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "5b49adae-3caf-450f-a764-45f757610e09"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_widget = pn.Row(loading_gif, pn.pane.Str('Processing request...',styles={'font-size': '12pt'}))\n",
    "display(display_widget) # loading screen while preparing next widget\n",
    "#resizing width to get better viewing experience\n",
    "img_width = 1500\n",
    "\n",
    "ori_resized = resize_and_save(original_dry, width=img_width)\n",
    "rec_resized = resize_and_save(original_flooded, width=img_width)\n",
    "display_widget.clear();\n",
    "#display_widget.append(pn.Swipe(recon_path_low, recon_path_high,slider_width=3, slider_color =\"#00fff2\"))\n",
    "display_widget.append(pn.Swipe(ori_resized, rec_resized,slider_width=3, slider_color =\"#00fff2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b084b4ec-ea1a-4ec4-bd47-46625d59f2f7",
   "metadata": {},
   "source": [
    "### before | after (reconstructed low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05ae3897-9c31-4e78-9348-56ac1f9f5c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='0c2c5cc2-4772-4ffb-a1df-cbab8b52a41d'>\n",
       "  <div id=\"c1518f7e-ffcd-426c-b996-78e4d13b5e84\" data-root-id=\"0c2c5cc2-4772-4ffb-a1df-cbab8b52a41d\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"8a860d6f-ef1c-476f-9281-740bec9981d7\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"0c2c5cc2-4772-4ffb-a1df-cbab8b52a41d\",\"attributes\":{\"name\":\"Row00198\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"3a31d0fd-7e18-435a-81b7-9ff5d4c6f5c9\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"5e87b18d-a36e-4cf2-ac8a-63f8dd568cde\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"7d387005-d212-4785-a01a-b1966ad7f2cd\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/dark.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"48103676-8617-4dab-8fa5-3309a181497b\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/theme/native.css\"}}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"4676cadf-bd3a-4333-b93f-39ed445a99b7\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3a31d0fd-7e18-435a-81b7-9ff5d4c6f5c9\"},{\"id\":\"7d387005-d212-4785-a01a-b1966ad7f2cd\"},{\"id\":\"48103676-8617-4dab-8fa5-3309a181497b\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/d/de/Ajax-loader.gif&quot;  style=&quot;max-width: 100%; max-height: 100%; object-fit: contain; width: auto; height: auto;&quot;&gt;&lt;/img&gt;\"}},{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"c5bfa593-27dd-409c-a974-7b41f6750eb9\",\"attributes\":{\"styles\":{\"type\":\"map\",\"entries\":[[\"font-size\",\"12pt\"]]},\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3a31d0fd-7e18-435a-81b7-9ff5d4c6f5c9\"},{\"id\":\"7d387005-d212-4785-a01a-b1966ad7f2cd\"},{\"id\":\"48103676-8617-4dab-8fa5-3309a181497b\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt;Processing request...&lt;/pre&gt;\"}}]}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"09103f1c-5f11-42e5-a173-4f952de706ab\",\"attributes\":{\"plot_id\":\"0c2c5cc2-4772-4ffb-a1df-cbab8b52a41d\",\"comm_id\":\"ed47334f2bc04d00b0cc39b87f0e40ce\",\"client_comm_id\":\"acd36cc650d149bc84d726f4ffd5eab6\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"8a860d6f-ef1c-476f-9281-740bec9981d7\",\"roots\":{\"0c2c5cc2-4772-4ffb-a1df-cbab8b52a41d\":\"c1518f7e-ffcd-426c-b996-78e4d13b5e84\"},\"root_ids\":[\"0c2c5cc2-4772-4ffb-a1df-cbab8b52a41d\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Row\n",
       "    [0] GIF(str)\n",
       "    [1] Str(str, styles={'font-size': '12pt'})"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "0c2c5cc2-4772-4ffb-a1df-cbab8b52a41d"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_widget = pn.Row(loading_gif, pn.pane.Str('Processing request...',styles={'font-size': '12pt'}))\n",
    "display(display_widget) # loading screen while preparing next widget\n",
    "#resizing width to get better viewing experience\n",
    "img_width = 1500\n",
    "\n",
    "ori_resized = resize_and_save(recon_dry, width=img_width)\n",
    "rec_resized = resize_and_save(recon_flooded, width=img_width)\n",
    "display_widget.clear();\n",
    "#display_widget.append(pn.Swipe(recon_path_low, recon_path_high,slider_width=3, slider_color =\"#00fff2\"))\n",
    "display_widget.append(pn.Swipe(ori_resized, rec_resized,slider_width=3, slider_color =\"#00fff2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf87680-5826-4a3f-9694-b3fdfadf9e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
